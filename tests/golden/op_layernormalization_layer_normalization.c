/*
 * Generated by emmtrix ONNX-to-C Code Generator (emx-onnx-cgen)
 *
 * Codegen settings:
 *   template_dir: package default
 *   emit_testbench: False
 *   restrict_arrays: True
 *   fp32_accumulation_strategy: fp64
 *   fp16_accumulation_strategy: fp32
 *   truncate_weights_after: n/a
 *   large_temp_threshold_bytes: 1024
 *   large_weight_threshold: 102400
 * Model checksum (sha256): da0ce981b3953a1748ec00b37e11ea699f928427ec5b1c8c5daf595834f47d62
 * Model name: model
 * Graph name: layernormalization_graph
 * Inputs: 3 Outputs: 1 Nodes: 1 Initializers: 0
 * IR version: 7
 * Model version: n/a
 * Domain: n/a
 * Producer: onnx2c (version: n/a)
 * Opset imports: ai.onnx=17
 * Description:
 *   n/a
 * Graph description:
 *   n/a
 * Metadata:
 *   n/a
 */

#include <stdint.h>
#include <math.h>

#ifndef idx_t
#define idx_t int32_t
#endif
#ifndef EMX_UNUSED
#if defined(__GNUC__) || defined(__clang__)
#define EMX_UNUSED __attribute__((unused))
#else
#define EMX_UNUSED
#endif
#endif

/*
 * Node 0:
 * OpType: LayerNormalization
 * Name: n/a
 * Inputs: in0, in1, in2
 * Outputs: out
 * Attrs:
 *   axis: 1
 *   epsilon: 9.999999747378752e-06
 */
static inline void node0_layernormalization(const float input0[2][3][4], const float scale[3][4], const float bias[3][4], float output[2][3][4]) {
    for (idx_t i0 = 0; i0 < 2; ++i0) {
        double sum = 0.0;
        for (idx_t i1 = 0; i1 < 3; ++i1) {
            for (idx_t i2 = 0; i2 < 4; ++i2) {
                sum += (double)input0[i0][i1][i2];
            }
        }
        double mean = sum / 12;
        double var = 0.0;
        for (idx_t i1 = 0; i1 < 3; ++i1) {
            for (idx_t i2 = 0; i2 < 4; ++i2) {
                double diff = (double)input0[i0][i1][i2] - mean;
                var += diff * diff;
            }
        }
        var = var / 12;
        double inv_std = 1.0 / sqrt(var + 9.9999997473787516e-06);
        for (idx_t i1 = 0; i1 < 3; ++i1) {
            for (idx_t i2 = 0; i2 < 4; ++i2) {
                double value = ((double)input0[i0][i1][i2] - mean) * inv_std;
                value = value * scale[i1][i2] + bias[i1][i2];
                output[i0][i1][i2] = value;
            }
        }
    }
}

_Bool model_load(const char *path) {
    (void)path;
    return 1;
}

void model(const float in0[restrict 2][3][4], const float in1[restrict 3][4], const float in2[restrict 3][4], float out[restrict 2][3][4]) {
    node0_layernormalization(in0, in1, in2, out);
}
