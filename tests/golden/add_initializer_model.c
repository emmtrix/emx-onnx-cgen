/*
 * Generated by emmtrix ONNX-to-C Code Generator (emx-onnx-cgen)
 *
 * Codegen settings:
 *   emit_testbench: False
 *   restrict_arrays: True
 *   fp32_accumulation_strategy: simple
 *   fp16_accumulation_strategy: fp32
 *   large_temp_threshold: 1024
 *   large_weight_threshold: 102400
 * Model checksum (sha256): 181ad20a39119718f4f1177a62deaeb93852afe1a88ec7821117e9c30de04f54
 * Model name: model
 * Graph name: add_init_graph
 * Inputs: 1 Outputs: 1 Nodes: 1 Initializers: 1
 * IR version: 7
 * Model version: n/a
 * Domain: n/a
 * Producer: emx-onnx-cgen (version: n/a)
 * Opset imports: ai.onnx=13
 * Description:
 *   n/a
 * Graph description:
 *   n/a
 * Metadata:
 *   n/a
 */

#include <stdint.h>
#include <math.h>
#include <float.h>

#ifndef idx_t
#define idx_t int32_t
#endif
#ifndef EMX_UNUSED
#if defined(__GNUC__) || defined(__clang__)
#define EMX_UNUSED __attribute__((unused))
#else
#define EMX_UNUSED
#endif
#endif
#ifndef EMX_STRING_MAX_LEN
#define EMX_STRING_MAX_LEN 256
#endif
#ifndef EMX_SEQUENCE_MAX_LEN
#define EMX_SEQUENCE_MAX_LEN 32
#endif

extern const float weight1_weight[2][3];

/*
 * Weight 1:
 * Name: weight1_weight
 * Shape: (2, 3)
 * Elements: 6
 * Dtype: float
 */
const EMX_UNUSED float weight1_weight[2][3] = {
    {
        0x1.99999ap-4f, 0x1.99999ap-3f, 0x1.333334p-2f
    },
    {
        0x1.99999ap-2f, 0x1.000000p-1f, 0x1.333334p-1f
    }
};

static inline float ref_scalar_f32_add(float a, float b) {
    return a + b;
}

/*
 * Node 0:
 * OpType: Add
 * Name: n/a
 * Inputs: in0, weight
 * Outputs: out
 * Attrs: n/a
 */
static inline void node0_add(const float input0[2][3], const float input1[2][3], float output[2][3]) {
    for (idx_t i0 = 0; i0 < 2; ++i0) {
        for (idx_t i1 = 0; i1 < 3; ++i1) {
            output[i0][i1] = ref_scalar_f32_add(input0[i0][i1], input1[i0][i1]);
        }
    }
}

_Bool model_load(const char *path) {
    (void)path;
    return 1;
}

void model(const float in0[restrict 2][3], float out[restrict 2][3]) {
    node0_add(in0, weight1_weight, out);
}
